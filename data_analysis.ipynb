{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG-Driven Portfolio Optimization: Personalized Factor Investing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "import transformers\n",
    "import os\n",
    "import datetime\n",
    "from lxml import etree\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I Data import by webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2024-10-24 already exists. Skipping insertion.\n"
     ]
    }
   ],
   "source": [
    "# Define URLs for different categories\n",
    "URLs = {\n",
    "    'MA': \"https://finance.yahoo.com/markets/stocks/most-active/\",\n",
    "    'TN': \"https://finance.yahoo.com/markets/stocks/trending/\",\n",
    "    'GA': \"https://finance.yahoo.com/markets/stocks/gainers/\",\n",
    "    'TL': \"https://finance.yahoo.com/markets/stocks/losers/\"\n",
    "}\n",
    "\n",
    "def fetch_and_parse(url):\n",
    "    page = requests.get(url).content\n",
    "    tree = etree.HTML(page)\n",
    "    nodes = tree.xpath(\"//*[contains(concat(' ', @class, ' '), concat(' ', 'yf-138ga19', ' '))]\")\n",
    "    texts = [node.text for node in nodes]\n",
    "    cleaned = [text.strip() for text in texts if text and text.strip()]\n",
    "    tickers = [cleaned[i] for i in range(0, len(cleaned), 2)]\n",
    "    return tickers\n",
    "\n",
    "def data_exists_for_today(conn, date):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM stock_categories WHERE date = ?\", (date,))\n",
    "    count = cursor.fetchone()[0]\n",
    "    return count > 0\n",
    "\n",
    "def main():\n",
    "    current_date = datetime.date.today().isoformat()\n",
    "    db_path = os.path.join(os.getcwd(), 'stock_data.db')\n",
    "\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Check if data for today already exists\n",
    "    if data_exists_for_today(conn, current_date):\n",
    "        print(f\"Data for {current_date} already exists. Skipping insertion.\")\n",
    "        conn.close()\n",
    "        return\n",
    "\n",
    "    # Fetch and parse data for each category\n",
    "    data = {category: fetch_and_parse(url) for category, url in URLs.items()}\n",
    "\n",
    "    # Create a set of all unique tickers\n",
    "    all_tickers = set()\n",
    "    for tickers in data.values():\n",
    "        all_tickers.update(tickers)\n",
    "\n",
    "    # Create a DataFrame with all tickers and categories\n",
    "    df = pd.DataFrame(index=sorted(all_tickers), columns=URLs.keys())\n",
    "\n",
    "    # Fill the DataFrame\n",
    "    for category, tickers in data.items():\n",
    "        df[category] = df.index.isin(tickers).astype(int)\n",
    "\n",
    "    # Reset index to make 'ticker' a column\n",
    "    df = df.reset_index().rename(columns={'index': 'ticker'})\n",
    "\n",
    "    # Display the first few rows of the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_path = os.path.join(os.getcwd(), 'stock_categories.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Data saved to {csv_path}\")\n",
    "\n",
    "    # Prepare data for insertion\n",
    "    data_to_insert = []\n",
    "    current_timestamp = datetime.datetime.now().isoformat()\n",
    "    for category, tickers in data.items():\n",
    "        for ticker in tickers:\n",
    "            data_to_insert.append((current_date, ticker, category, current_timestamp))\n",
    "\n",
    "    # Create table if it doesn't exist\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS stock_categories\n",
    "    (date TEXT, ticker TEXT, category TEXT, timestamp TEXT)\n",
    "    ''')\n",
    "\n",
    "    # Insert data into database\n",
    "    query = '''\n",
    "    INSERT INTO stock_categories (date, ticker, category, timestamp)\n",
    "    VALUES (?, ?, ?, ?)\n",
    "    '''\n",
    "    cursor.executemany(query, data_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Data inserted successfully into {db_path}\")\n",
    "\n",
    "    # Check content of database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT ticker\n",
    "    FROM stock_categories\n",
    "    WHERE date = ?\n",
    "      AND category = 'MA'\n",
    "    ORDER BY ticker;\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (current_date,))\n",
    "\n",
    "    # Fetch and print the results\n",
    "    results = cursor.fetchall()\n",
    "    print(f\"\\nTickers in the 'MA' category for {current_date}:\")\n",
    "    for row in results:\n",
    "        print(row[0])\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tickers in the 'MA' category for 2024-10-24:\n",
      "AAL\n",
      "AAPL\n",
      "AGNC\n",
      "ALTM\n",
      "AMZN\n",
      "BAC\n",
      "BBD\n",
      "CLSK\n",
      "DJT\n",
      "F\n",
      "GRAB\n",
      "INTC\n",
      "IONQ\n",
      "KO\n",
      "LCID\n",
      "MARA\n",
      "NIO\n",
      "NVDA\n",
      "OKLO\n",
      "PLTR\n",
      "PTON\n",
      "SNAP\n",
      "SOFI\n",
      "T\n",
      "TSLA\n"
     ]
    }
   ],
   "source": [
    "# Check content of database\n",
    "# Connect to the SQLite database\n",
    "db_path = os.path.join(os.getcwd(), 'stock_data.db')\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get today's date in ISO format\n",
    "today = datetime.date.today().isoformat()\n",
    "\n",
    "# Execute the SQL query\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT ticker\n",
    "FROM stock_categories\n",
    "WHERE date = ?\n",
    "  AND category = 'MA'\n",
    "ORDER BY ticker;\n",
    "\"\"\"\n",
    "cursor.execute(query, (today,))\n",
    "\n",
    "# Fetch and print the results\n",
    "results = cursor.fetchall()\n",
    "print(f\"\\nTickers in the 'MA' category for {today}:\")\n",
    "for row in results:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['date', 'ticker', 'category', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "# Execute a query to get some rows from the table\n",
    "cursor.execute(\"SELECT * FROM stock_categories LIMIT 1\")\n",
    "\n",
    "# Extract column names using cursor.description\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: NVDA\n",
      "Categories: ['MA']\n",
      "Ticker: T\n",
      "Categories: ['MA', 'TN', 'GA']\n",
      "Ticker: TSLA\n",
      "Categories: ['MA', 'TN']\n",
      "Ticker: GRAB\n",
      "Categories: ['MA']\n",
      "Ticker: DJT\n",
      "Categories: ['MA', 'GA']\n",
      "Ticker: MARA\n",
      "Categories: ['MA']\n",
      "Ticker: AAPL\n",
      "Categories: ['MA']\n",
      "Ticker: LCID\n",
      "Categories: ['MA']\n",
      "Ticker: INTC\n",
      "Categories: ['MA']\n",
      "Ticker: AGNC\n",
      "Categories: ['MA']\n",
      "Ticker: SOFI\n",
      "Categories: ['MA']\n",
      "Ticker: NIO\n",
      "Categories: ['MA']\n",
      "Ticker: OKLO\n",
      "Categories: ['MA', 'TL']\n",
      "Ticker: F\n",
      "Categories: ['MA']\n",
      "Ticker: PLTR\n",
      "Categories: ['MA']\n",
      "Ticker: CLSK\n",
      "Categories: ['MA']\n",
      "Ticker: PTON\n",
      "Categories: ['MA', 'TN', 'GA']\n",
      "Ticker: SNAP\n",
      "Categories: ['MA']\n",
      "Ticker: IONQ\n",
      "Categories: ['MA']\n",
      "Ticker: BBD\n",
      "Categories: ['MA']\n",
      "Ticker: BAC\n",
      "Categories: ['MA']\n",
      "Ticker: AAL\n",
      "Categories: ['MA']\n",
      "Ticker: ALTM\n",
      "Categories: ['MA']\n",
      "Ticker: AMZN\n",
      "Categories: ['MA']\n",
      "Ticker: KO\n",
      "Categories: ['MA']\n",
      "Ticker: IBM\n",
      "Categories: ['TN']\n",
      "Ticker: LRCX\n",
      "Categories: ['TN']\n",
      "Ticker: NOW\n",
      "Categories: ['TN']\n",
      "Ticker: SAVE\n",
      "Categories: ['TN']\n",
      "Ticker: QS\n",
      "Categories: ['TN']\n",
      "Ticker: VKTX\n",
      "Categories: ['TN']\n",
      "Ticker: TMUS\n",
      "Categories: ['TN']\n",
      "Ticker: ARM\n",
      "Categories: ['TN', 'TL']\n",
      "Ticker: NEM\n",
      "Categories: ['TN']\n",
      "Ticker: PANW\n",
      "Categories: ['TN']\n",
      "Ticker: CLS\n",
      "Categories: ['TN']\n",
      "Ticker: BA\n",
      "Categories: ['TN']\n",
      "Ticker: NEP\n",
      "Categories: ['TN']\n",
      "Ticker: ALGN\n",
      "Categories: ['TN']\n",
      "Ticker: URI\n",
      "Categories: ['TN']\n",
      "Ticker: LVS\n",
      "Categories: ['TN']\n",
      "Ticker: WHR\n",
      "Categories: ['TN']\n",
      "Ticker: LRHC\n",
      "Categories: ['TN']\n",
      "Ticker: AMAT\n",
      "Categories: ['TN']\n",
      "Ticker: UAVS\n",
      "Categories: ['TN']\n",
      "Ticker: META\n",
      "Categories: ['TN']\n",
      "Ticker: VRAX\n",
      "Categories: ['TN']\n",
      "Ticker: LRN\n",
      "Categories: ['GA']\n",
      "Ticker: JBT\n",
      "Categories: ['GA']\n",
      "Ticker: VICR\n",
      "Categories: ['GA']\n",
      "Ticker: VMI\n",
      "Categories: ['GA']\n",
      "Ticker: LAD\n",
      "Categories: ['GA']\n",
      "Ticker: ESI\n",
      "Categories: ['GA']\n",
      "Ticker: DJTWW\n",
      "Categories: ['GA']\n",
      "Ticker: PTCT\n",
      "Categories: ['GA']\n",
      "Ticker: NTRS\n",
      "Categories: ['GA']\n",
      "Ticker: TDY\n",
      "Categories: ['GA']\n",
      "Ticker: EWBC\n",
      "Categories: ['GA']\n",
      "Ticker: PKG\n",
      "Categories: ['GA']\n",
      "Ticker: HRI\n",
      "Categories: ['GA']\n",
      "Ticker: WPP\n",
      "Categories: ['GA']\n",
      "Ticker: RNST\n",
      "Categories: ['GA']\n",
      "Ticker: SW\n",
      "Categories: ['GA']\n",
      "Ticker: ALVO\n",
      "Categories: ['GA']\n",
      "Ticker: TNL\n",
      "Categories: ['GA']\n",
      "Ticker: TXN\n",
      "Categories: ['GA']\n",
      "Ticker: VEON\n",
      "Categories: ['GA']\n",
      "Ticker: LI\n",
      "Categories: ['GA']\n",
      "Ticker: RBGLY\n",
      "Categories: ['GA']\n",
      "Ticker: ENPH\n",
      "Categories: ['TL']\n",
      "Ticker: TAL\n",
      "Categories: ['TL']\n",
      "Ticker: BPOP\n",
      "Categories: ['TL']\n",
      "Ticker: HIMS\n",
      "Categories: ['TL']\n",
      "Ticker: NUVL\n",
      "Categories: ['TL']\n",
      "Ticker: EDU\n",
      "Categories: ['TL']\n",
      "Ticker: NBIS\n",
      "Categories: ['TL']\n",
      "Ticker: STX\n",
      "Categories: ['TL']\n",
      "Ticker: ZIM\n",
      "Categories: ['TL']\n",
      "Ticker: MALRY\n",
      "Categories: ['TL']\n",
      "Ticker: MANH\n",
      "Categories: ['TL']\n",
      "Ticker: BE\n",
      "Categories: ['TL']\n",
      "Ticker: EVR\n",
      "Categories: ['TL']\n",
      "Ticker: TWST\n",
      "Categories: ['TL']\n",
      "Ticker: INSW\n",
      "Categories: ['TL']\n",
      "Ticker: HMY\n",
      "Categories: ['TL']\n",
      "Ticker: ASTS\n",
      "Categories: ['TL', 'TN']\n",
      "Ticker: SSL\n",
      "Categories: ['TL']\n",
      "Ticker: ASTH\n",
      "Categories: ['TL']\n",
      "Ticker: COIN\n",
      "Categories: ['TL']\n",
      "Ticker: TRMD\n",
      "Categories: ['TL']\n",
      "Ticker: ODFL\n",
      "Categories: ['TL']\n",
      "Ticker: NTLA\n",
      "Categories: ['TL']\n",
      "Ticker: UBER\n",
      "Categories: ['TN']\n",
      "Ticker: MAT\n",
      "Categories: ['TN']\n"
     ]
    }
   ],
   "source": [
    "# Get all unique tickers from the database\n",
    "cursor.execute(\"SELECT DISTINCT ticker FROM stock_categories\")\n",
    "tickers = cursor.fetchall()\n",
    "\n",
    "# Iterate over each ticker to get unique categories for each ticker\n",
    "for ticker in tickers:\n",
    "    specific_ticker = ticker[0]  # Extract the ticker from the tuple\n",
    "\n",
    "    # Get all unique categories for the specific ticker\n",
    "    cursor.execute(\"SELECT DISTINCT category FROM stock_categories WHERE ticker = ?\", (specific_ticker,))\n",
    "    categories = cursor.fetchall()\n",
    "\n",
    "    # Print the results for each ticker\n",
    "    print(f\"Ticker: {specific_ticker}\")\n",
    "    print(\"Categories:\", [category[0] for category in categories])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Market capitalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<span class=\"label yf-mrt107\">Market Cap (intraday)</span>\n",
    "#DO IT WITH JSON\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Sustainability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total ESG Risk Score: <div class=\"scoreRank yf-y3c2sq\"><h4 class=\"border yf-y3c2sq\">23.9</h4> <span class=\"yf-y3c2sq\">44th percentile</span></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_parse_sust(url_sust):\n",
    "    page = requests.get(url_sust).content\n",
    "    tree = etree.HTML(page)\n",
    "    nodes = tree.xpath(\"//*[contains(concat( ' ', @class, ' ' ), concat( ' ', 'yf-y3c2sq', ' ' ))]\")\n",
    "    texts = [node.text for node in nodes]\n",
    "    cleaned = [text.strip() for text in texts if text and text.strip()]\n",
    "    result = [cleaned[i] for i in range(0, len(cleaned), 2)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data was fetched from the URL.\n"
     ]
    }
   ],
   "source": [
    "# Example URL for scraping\n",
    "url = 'https://finance.yahoo.com/quote/NVDA/sustainability/'\n",
    "\n",
    "# Fetch and parse sustainability data\n",
    "sustainability_data = fetch_and_parse_sust(url)\n",
    "\n",
    "# Check if data is fetched successfully\n",
    "if sustainability_data:\n",
    "    # Create a DataFrame from the fetched data\n",
    "    df = pd.DataFrame(sustainability_data, columns=['Sustainability Metric'])\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No data was fetched from the URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/3hy0z8052093y_1_c5sjdnc00000gn/T/ipykernel_18150/1387931352.py:40: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  element = soup.find(text=label)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create the sustainability_data table with appropriate data types\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS sustainability_data (\n",
    "    ticker TEXT PRIMARY KEY,\n",
    "    total_esg_risk_score REAL,\n",
    "    environmental_risk_score REAL,\n",
    "    social_risk_score REAL,\n",
    "    governance_risk_score REAL\n",
    ")\n",
    "''')\n",
    "\n",
    "def fetch_sustainability_data(ticker):\n",
    "    url = f'https://finance.yahoo.com/quote/{ticker}/sustainability/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Use appropriate selectors based on actual HTML structure\n",
    "    total_esg_risk_score = soup.find(text='Total ESG Risk Score').find_next('span').get_text(strip=True)\n",
    "    environmental_risk_score = soup.find(text='Environmental Risk Score').find_next('span').get_text(strip=True)\n",
    "    social_risk_score = soup.find(text='Social Risk Score').find_next('span').get_text(strip=True)\n",
    "    governance_risk_score = soup.find(text='Governance Risk Score').find_next('span').get_text(strip=True)\n",
    "    \n",
    "    # Return the scores as a dictionary\n",
    "    return {\n",
    "        'total_esg_risk_score': float(total_esg_risk_score),\n",
    "        'environmental_risk_score': float(environmental_risk_score),\n",
    "        'social_risk_score': float(social_risk_score),\n",
    "        'governance_risk_score': float(governance_risk_score)\n",
    "    }\n",
    "\n",
    "def fetch_sustainability_data(ticker):\n",
    "    url = f'https://finance.yahoo.com/quote/{ticker}/sustainability/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    def get_score(label):\n",
    "        element = soup.find(text=label)\n",
    "        return float(element.find_next('span').get_text(strip=True)) if element else None\n",
    "    \n",
    "    return {\n",
    "        'total_esg_risk_score': get_score('Total ESG Risk Score'),\n",
    "        'environmental_risk_score': get_score('Environmental Risk Score'),\n",
    "        'social_risk_score': get_score('Social Risk Score'),\n",
    "        'governance_risk_score': get_score('Governance Risk Score')\n",
    "    }\n",
    "\n",
    "tickers = ['NVDA', 'AAPL', 'GOOGL']  # Example tickers\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('sustainability.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = fetch_sustainability_data(ticker)\n",
    "    if all(data.values()):  # Check if all values are present\n",
    "        cursor.execute('''\n",
    "        INSERT INTO sustainability_data (ticker, total_esg_risk_score, environmental_risk_score, social_risk_score, governance_risk_score)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ON CONFLICT(ticker) DO UPDATE SET\n",
    "            total_esg_risk_score=excluded.total_esg_risk_score,\n",
    "            environmental_risk_score=excluded.environmental_risk_score,\n",
    "            social_risk_score=excluded.social_risk_score,\n",
    "            governance_risk_score=excluded.governance_risk_score\n",
    "        ''', (ticker, \n",
    "              data['total_esg_risk_score'], \n",
    "              data['environmental_risk_score'], \n",
    "              data['social_risk_score'], \n",
    "              data['governance_risk_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['ticker', 'total_esg_risk_score', 'environmental_risk_score', 'social_risk_score', 'governance_risk_score']\n"
     ]
    }
   ],
   "source": [
    "# Execute a query to select all data from the sustainability_data table\n",
    "cursor.execute('SELECT * FROM sustainability_data')\n",
    "\n",
    "# Fetch all rows from the executed query\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Get column names from the cursor description\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "# Print column names\n",
    "print(\"Column Names:\", column_names)\n",
    "\n",
    "# Print each row of data\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
